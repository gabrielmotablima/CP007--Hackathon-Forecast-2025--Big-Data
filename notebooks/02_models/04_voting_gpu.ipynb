{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703f0c27",
   "metadata": {},
   "source": [
    "# Ensemble Demand Forecasting with Voting Regressor\n",
    "\n",
    "This notebook uses Optuna to optimize a `VotingRegressor` ensemble, which combines predictions from XGBoost, RandomForest, and SVR models. The goal is to find the best hyperparameters for each base model and the optimal weights for combining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2285e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import yaml\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Modeling & Optimization\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "import optuna\n",
    "\n",
    "# Our functions\n",
    "import utils.voting_utils_gpu as utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21530e28",
   "metadata": {},
   "source": [
    "# 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eacba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"params/voting_params.yml\", \"r\") as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "RANDOM_STATE = configs['RANDOM_STATE']\n",
    "NUMBER_OF_FOLDS = configs['NUMBER_OF_FOLDS']\n",
    "FEATURE_COLUMNS = configs['FEATURES']\n",
    "LABEL_COLUMNS = configs['TARGET']\n",
    "PREPROCESSING = configs['PREPROCESSING']\n",
    "OPTUNA_PARAMS = configs['OPTUNA_PARAMS']\n",
    "MODEL_RANGE_PARAMS = OPTUNA_PARAMS['MODELS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac4e26",
   "metadata": {},
   "source": [
    "# 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef02f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading and preparing data...\")\n",
    "df = pd.read_parquet('../../data/processed/processed_data.parquet')\n",
    "df['week_of_year'] = df['week_of_year'].astype(int)\n",
    "df = df.sort_values([\"week_of_year\", \"internal_product_id\", \"internal_store_id\"]).reset_index(drop=True)\n",
    "\n",
    "# Manual Pre-processing from original notebook\n",
    "df = df[~pd.isna(df['premise'])]\n",
    "df['premise'] = df['premise'].map({'Off Premise': 1, 'On Premise': 0}).astype(int)\n",
    "cols_sum = df.columns[df.columns.str.contains(\"sum\")]\n",
    "df[cols_sum] = df[cols_sum].fillna(0)\n",
    "\n",
    "print(f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7252a21",
   "metadata": {},
   "source": [
    "# 3. Feature Separation and Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe99bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = [col for col in df[FEATURE_COLUMNS].select_dtypes(np.number).columns if col not in PREPROCESSING.get('CYCLICAL_FEATURES', {})]\n",
    "CATEGORICAL_COLUMNS = [col for col in df[FEATURE_COLUMNS].select_dtypes('object').columns]\n",
    "\n",
    "# Use data before December for training/validation\n",
    "X_train = df.loc[df.month != 12, FEATURE_COLUMNS]\n",
    "y_train = df.loc[df.month != 12, [LABEL_COLUMNS]]\n",
    "\n",
    "# Time-series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=NUMBER_OF_FOLDS)\n",
    "\n",
    "print(\"Data split and CV folds created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea75f6",
   "metadata": {},
   "source": [
    "## 4. Optimize Ensemble with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a57e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(study_name='voting_regressor_optimization', directions=['minimize', 'minimize'])\n",
    "study.set_metric_names([\"score_validation\", \"score_overfitting\"])\n",
    "\n",
    "objective_function = utils.create_objective_function(\n",
    "    hyperparam_ranges=MODEL_RANGE_PARAMS,\n",
    "    tscv=tscv,\n",
    "    x_data=[X_train, y_train],\n",
    "    columns_to_use=[FEATURE_COLUMNS, LABEL_COLUMNS, NUMERIC_COLUMNS, CATEGORICAL_COLUMNS],\n",
    "    preprocessing=PREPROCESSING,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "study.optimize(objective_function, n_trials=OPTUNA_PARAMS['TRIALS'])\n",
    "\n",
    "print(\"Optimization finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, best_params = utils.get_best_params(study)\n",
    "print(\"Best parameters found for the Voting Regressor ensemble:\")\n",
    "print(json.dumps(best_params, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee4401",
   "metadata": {},
   "source": [
    "## 5. Fit Final Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting final VotingRegressor with all available data...\")\n",
    "\n",
    "# Use all data from Jan-Dec for the final model\n",
    "X_train_full = df[FEATURE_COLUMNS]\n",
    "y_train_full = df[[LABEL_COLUMNS]]\n",
    "\n",
    "# --- Reconstruct the optimized models and VotingRegressor ---\n",
    "\n",
    "# Extract best params for each model\n",
    "xgb_final_params = {k.replace('xgb_', ''): v for k, v in best_params.items() if k.startswith('xgb_')}\n",
    "rf_final_params = {k.replace('rf_', ''): v for k, v in best_params.items() if k.startswith('rf_')}\n",
    "svr_final_params = {k.replace('svr_', ''): v for k, v in best_params.items() if k.startswith('svr_')}\n",
    "weights_final = [best_params['w_xgb'], best_params['w_rf'], best_params['w_svr']]\n",
    "\n",
    "# Instantiate final models\n",
    "final_xgb = XGBRegressor(**xgb_final_params, device='cuda', tree_method='hist', random_state=RANDOM_STATE)\n",
    "final_rf = RandomForestRegressor(**rf_final_params, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "final_svr = SVR(**svr_final_params)\n",
    "\n",
    "# Create the final Voting Regressor\n",
    "final_voting_regressor = VotingRegressor(\n",
    "    estimators=[('xgb', final_xgb), ('rf', final_rf), ('svr', final_svr)],\n",
    "    weights=weights_final,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Final ensemble configured:\")\n",
    "print(final_voting_regressor)\n",
    "\n",
    "# --- Build and fit the final pipeline ---\n",
    "pipe_preproc = utils.create_preprocessing_pipeline(PREPROCESSING, NUMERIC_COLUMNS, CATEGORICAL_COLUMNS)\n",
    "ttr = TransformedTargetRegressor(regressor=final_voting_regressor, func=np.log1p, inverse_func=np.expm1)\n",
    "final_pipeline = Pipeline(steps=[('preprocessor', pipe_preproc), ('model', ttr)])\n",
    "\n",
    "final_pipeline.fit(X_train_full, y_train_full.values.ravel())\n",
    "\n",
    "print(\"\\nFinal pipeline fitted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b99db",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9982589",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = f\"outputs/{dt.datetime.now().strftime('%Y%m%d%H%M')}_VOTING_REGRESSOR/\"\n",
    "output_model_directory = os.path.join(output_directory, 'model')\n",
    "output_params_directory = os.path.join(output_directory, 'params')\n",
    "output_optuna_directory = os.path.join(output_directory, 'study')\n",
    "\n",
    "for directory in [output_model_directory, output_params_directory, output_optuna_directory]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(f\"Created output directory: {output_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final pipeline\n",
    "with open(os.path.join(output_model_directory, 'pipeline.pkl'), 'wb') as f:\n",
    "    pickle.dump(final_pipeline, f)\n",
    "\n",
    "# Save the parameters used\n",
    "with open(os.path.join(output_params_directory, 'experiment_params.json'), 'w') as f:\n",
    "    # Convert numpy types to native python types for JSON serialization\n",
    "    serializable_params = {k: (float(v) if isinstance(v, (np.floating, np.integer)) else v) for k, v in best_params.items()}\n",
    "    configs_all = {**configs, 'BEST_PARAMS': serializable_params}\n",
    "    json.dump(configs_all, f, indent=4)\n",
    "\n",
    "# Save the Optuna study object\n",
    "with open(os.path.join(output_optuna_directory, 'study.pkl'), 'wb') as f:\n",
    "    pickle.dump(study, f)\n",
    "\n",
    "print(\"All artifacts saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
