{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35d83993"
      },
      "source": [
        "# BUILD DATA FOR PRODUCTION PREDICTIONS"
      ],
      "id": "35d83993"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e1847e3"
      },
      "source": [
        "## IMPORT LIBRARIES"
      ],
      "id": "3e1847e3"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76386bc9"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import numpy as np"
      ],
      "id": "76386bc9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SETUP VARIABLES"
      ],
      "metadata": {
        "id": "38-ddWjva_02"
      },
      "id": "38-ddWjva_02"
    },
    {
      "cell_type": "code",
      "source": [
        "LEADING_MONTHS = 1\n",
        "LEADING_WEEKS = 5"
      ],
      "metadata": {
        "id": "H-RtJ2aiaY_8"
      },
      "id": "H-RtJ2aiaY_8",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3KdoeuIDcl3"
      },
      "source": [
        "## DATA READING"
      ],
      "id": "z3KdoeuIDcl3"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JWbzM1FODf1A"
      },
      "outputs": [],
      "source": [
        "df_store = pl.read_parquet('../../data/raw/part-00000-tid-2779033056155408584-f6316110-4c9a-4061-ae48-69b77c7c8c36-4-1-c000.snappy.parquet')\n",
        "df_transaction = pl.read_parquet('../../data/raw/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet')\n",
        "df_product = pl.read_parquet('../../data/raw/part-00000-tid-7173294866425216458-eae53fbf-d19e-4130-ba74-78f96b9675f1-4-1-c000.snappy.parquet')\n",
        "df_zipcode = pl.read_csv('../../data/raw/georef-zipcode.csv', separator=';')\n",
        "df_holiday = pl.read_csv('../../data/processed/processed_usa_holiday.csv', separator=',')"
      ],
      "id": "JWbzM1FODf1A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emZQSGMoD2fN"
      },
      "source": [
        "## UNIFIYNG DATASETS"
      ],
      "id": "emZQSGMoD2fN"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "50kNR3edoz-F"
      },
      "outputs": [],
      "source": [
        "df = df_transaction.join(\n",
        "    df_store,\n",
        "    left_on=\"internal_store_id\",\n",
        "    right_on=\"pdv\",\n",
        "    how='left'\n",
        ").join(\n",
        "    df_product,\n",
        "    left_on=\"internal_product_id\",\n",
        "    right_on=\"produto\",\n",
        "    how='left'\n",
        ")"
      ],
      "id": "50kNR3edoz-F"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRtfHKE6EHqz"
      },
      "source": [
        "## DATA WRANGLING"
      ],
      "id": "eRtfHKE6EHqz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaerDLe8EM2p"
      },
      "source": [
        "### Dropping negative and rounding values from quantity"
      ],
      "id": "BaerDLe8EM2p"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W9ebElZSpRJf"
      },
      "outputs": [],
      "source": [
        "df = df.filter(df['quantity'] >= 0)\n",
        "df = df.with_columns(df['quantity'].round().cast(pl.Int64))"
      ],
      "id": "W9ebElZSpRJf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snurt0Y0ykX7"
      },
      "source": [
        "### Treating the overwhelming outliers of 2022-09-11"
      ],
      "id": "snurt0Y0ykX7"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vBkFAWAhyMdH"
      },
      "outputs": [],
      "source": [
        "# Remove from day 2022-09-11 the products with quantity greater than the percentile 75\n",
        "# and products appearing for the first time\n",
        "\n",
        "outlier_date = pl.lit('2022-09-11').str.to_date()\n",
        "\n",
        "outlier_products = df.filter(\n",
        "    pl.col('transaction_date') == outlier_date\n",
        ")['internal_product_id'].unique()\n",
        "\n",
        "normal_products = df.filter(\n",
        "    (pl.col('internal_product_id').is_in(outlier_products)) &\n",
        "    (pl.col('transaction_date') < outlier_date)\n",
        ")['internal_product_id'].unique()\n",
        "\n",
        "# Calculate the 75th percentile of quantity for the outlier date\n",
        "outlier_percentile_75 = df.filter(\n",
        "    pl.col('transaction_date') == outlier_date\n",
        ").select(\n",
        "    pl.col('quantity').quantile(0.75, interpolation='linear')\n",
        ").item()\n",
        "\n",
        "# Filter the DataFrame\n",
        "df = df.filter(\n",
        "    (pl.col('transaction_date') != outlier_date) |\n",
        "    (\n",
        "        pl.col('quantity').le(outlier_percentile_75) &\n",
        "        pl.col('internal_product_id').is_in(normal_products)\n",
        "    )\n",
        ")"
      ],
      "id": "vBkFAWAhyMdH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtGuBbBfArc0"
      },
      "source": [
        "### Transform temporal features"
      ],
      "id": "WtGuBbBfArc0"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fCPWBTbtpdFW"
      },
      "outputs": [],
      "source": [
        "df = df.with_columns([\n",
        "    pl.col('transaction_date').dt.month().alias('month'),\n",
        "    pl.col('transaction_date').dt.strftime(\"%U\").cast(pl.Int64).alias('week_of_year')\n",
        "])"
      ],
      "id": "fCPWBTbtpdFW"
    },
    {
      "cell_type": "code",
      "source": [
        "max_week = df[\"week_of_year\"].max()\n",
        "max_month = df[\"month\"].max()"
      ],
      "metadata": {
        "id": "iuB82tF6Zw01"
      },
      "id": "iuB82tF6Zw01",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTOfLA29EpvT"
      },
      "source": [
        "## FEATURE ENGINEERING"
      ],
      "id": "DTOfLA29EpvT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4246z2MRRRB2"
      },
      "source": [
        "### Setup variables for feature engineering"
      ],
      "id": "4246z2MRRRB2"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sglVLVZrNxdB"
      },
      "outputs": [],
      "source": [
        "cols = ['quantity','gross_value','net_value','gross_profit','discount']\n",
        "keys = [\n",
        "    'internal_product_id', 'internal_store_id', 'distributor_id',\n",
        "    'premise', 'categoria_pdv', 'zipcode', 'tipos', 'label', 'subcategoria',\n",
        "    'marca', 'fabricante', 'month', 'week_of_year', 'city'\n",
        "]\n",
        "city_partition = ['internal_product_id', 'city']\n",
        "city_month_keys = ['internal_product_id', 'city', 'month']\n",
        "city_week_keys = ['internal_product_id', 'city', 'week_of_year']\n",
        "pdv_week_keys = ['internal_product_id', 'internal_store_id', 'week_of_year']\n",
        "product_city_partition = ['internal_product_id', 'city']\n",
        "product_pdv_partition = ['internal_product_id', 'internal_store_id']"
      ],
      "id": "sglVLVZrNxdB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc9coo1SElVp"
      },
      "source": [
        "### Finding city by zipcode"
      ],
      "id": "jc9coo1SElVp"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UTmYkCFDueJD"
      },
      "outputs": [],
      "source": [
        "df_zipcode = df_zipcode.rename({'Zip Code': 'zipcode', 'Official USPS city name': 'city'})\n",
        "df = df.join(df_zipcode.select(['zipcode', 'city']), on='zipcode', how='left')"
      ],
      "id": "UTmYkCFDueJD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting USA holidays"
      ],
      "metadata": {
        "id": "4iSv4JOpGiHP"
      },
      "id": "4iSv4JOpGiHP"
    },
    {
      "cell_type": "code",
      "source": [
        "df_holiday = df_holiday.with_columns([\n",
        "    pl.col('Date').str.to_date().alias('Date'),\n",
        "    pl.lit(1).alias('holiday')\n",
        "])\n",
        "\n",
        "df = df.join(\n",
        "    df_holiday.select(['Date', 'holiday']),\n",
        "    left_on='transaction_date',\n",
        "    right_on='Date',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "df = df.with_columns(\n",
        "    pl.col('holiday').fill_null(0)\n",
        ")"
      ],
      "metadata": {
        "id": "mrKRfkiWGhq1"
      },
      "execution_count": 11,
      "outputs": [],
      "id": "mrKRfkiWGhq1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Droping some columns"
      ],
      "metadata": {
        "id": "TvFGzF-OSY_O"
      },
      "id": "TvFGzF-OSY_O"
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['taxes','categoria','descricao','reference_date', 'transaction_date'])"
      ],
      "metadata": {
        "id": "WJZmUBH1Sarn"
      },
      "execution_count": 12,
      "outputs": [],
      "id": "WJZmUBH1Sarn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating new values for prediction"
      ],
      "metadata": {
        "id": "LOL1ZJGaRLj5"
      },
      "id": "LOL1ZJGaRLj5"
    },
    {
      "cell_type": "code",
      "source": [
        "df_distinct = df.filter(df['month'] == max_month)[[\n",
        "    'internal_product_id',\n",
        "    'internal_store_id',\n",
        "    'distributor_id',\n",
        "    'premise',\n",
        "    'categoria_pdv',\n",
        "    'zipcode',\n",
        "    'tipos',\n",
        "    'label',\n",
        "    'subcategoria',\n",
        "    'marca',\n",
        "    'fabricante',\n",
        "    'city',\n",
        "    'holiday'\n",
        "]].unique().with_columns(\n",
        "    pl.lit(None).cast(pl.Int64).alias('quantity'),\n",
        "    pl.lit(None).cast(pl.Float64).alias('gross_value'),\n",
        "    pl.lit(None).cast(pl.Float64).alias('net_value'),\n",
        "    pl.lit(None).cast(pl.Float64).alias('gross_profit'),\n",
        "    pl.lit(None).cast(pl.Float64).alias('discount')\n",
        ")\n",
        "\n",
        "df_new = pl.concat([\n",
        "    df_distinct.with_columns(\n",
        "        pl.lit(max_month+1).cast(pl.Int8).alias('month'),\n",
        "        pl.lit(max_week+i).cast(pl.Int64).alias('week_of_year')\n",
        "    ) for i in range(1, LEADING_WEEKS+1)\n",
        "]).select([\n",
        "    'internal_store_id',\n",
        "    'internal_product_id',\n",
        "    'distributor_id',\n",
        "    'quantity',\n",
        "    'gross_value',\n",
        "    'net_value',\n",
        "    'gross_profit',\n",
        "    'discount',\n",
        "    'premise',\n",
        "    'categoria_pdv',\n",
        "    'zipcode',\n",
        "    'tipos',\n",
        "    'label',\n",
        "    'subcategoria',\n",
        "    'marca',\n",
        "    'fabricante',\n",
        "    'month',\n",
        "    'week_of_year',\n",
        "    'city',\n",
        "    'holiday'\n",
        "])\n",
        "\n",
        "df = pl.concat([df.filter(pl.col('month') == max_month), df_new])"
      ],
      "metadata": {
        "id": "i10KlbFR97sT"
      },
      "id": "i10KlbFR97sT",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEs1OM-3MjQm"
      },
      "source": [
        "### Creating Average numbers for skus purchased per city month"
      ],
      "id": "YEs1OM-3MjQm"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IXNfXpxSMwyD"
      },
      "outputs": [],
      "source": [
        "monthly_aggs = []\n",
        "for c in cols:\n",
        "    monthly_aggs += [\n",
        "        pl.col(c).sum().alias(f\"monthly_{c}_sum\"),\n",
        "    ]\n",
        "\n",
        "monthly_totals = df.group_by(city_month_keys).agg(monthly_aggs)\n",
        "\n",
        "monthly_shifts = []\n",
        "monthly_shifts_names = []\n",
        "for c in cols:\n",
        "    monthly_shifts += [\n",
        "        pl.col(f\"monthly_{c}_sum\").shift(n=1).over(product_city_partition).alias(f\"previous_month_{c}_sum\"),\n",
        "    ]\n",
        "    monthly_shifts_names += [\n",
        "        f\"previous_month_{c}_sum\",\n",
        "    ]\n",
        "\n",
        "previous_month_values = monthly_totals.sort(\"month\").with_columns(monthly_shifts)"
      ],
      "id": "IXNfXpxSMwyD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating shifting numbers for last 5 quantity sales for each product-PDV"
      ],
      "metadata": {
        "id": "yQ8mdMBvNHzU"
      },
      "id": "yQ8mdMBvNHzU"
    },
    {
      "cell_type": "code",
      "source": [
        "quantity_totals = df.group_by(pdv_week_keys).agg(\n",
        "    pl.col('quantity').sum().alias('quantity')\n",
        ").with_columns(\n",
        "    pl.when(pl.col('quantity') == 0).then(None).otherwise(pl.col('quantity')).alias('quantity')\n",
        ")\n",
        "\n",
        "quantity_shifts = [\n",
        "    pl.col(\"quantity\").shift(n=i).over(\n",
        "        product_pdv_partition\n",
        "    ).alias(f\"quantity_lag{i}\") for i in range(1, LEADING_WEEKS+1)\n",
        "]\n",
        "quantity_shifts_names = [\n",
        "    f\"quantity_lag{i}\" for i in range(1, LEADING_WEEKS+1)\n",
        "]\n",
        "quantity_nulls = [\n",
        "    pl.when(\n",
        "        pl.col(f\"quantity_lag{i}\") == 0\n",
        "    ).then(\n",
        "        None\n",
        "    ).otherwise(\n",
        "        pl.col(f\"quantity_lag{i}\")\n",
        "    ).alias(f\"quantity_lag{i}\") for i in range(1, LEADING_WEEKS+1)\n",
        "]\n",
        "\n",
        "previous_quantity_values = quantity_totals.sort(\n",
        "    pdv_week_keys\n",
        ").with_columns(quantity_shifts).with_columns(\n",
        "    quantity_nulls\n",
        ")"
      ],
      "metadata": {
        "id": "WIUj3AAiNHAf"
      },
      "execution_count": 15,
      "outputs": [],
      "id": "WIUj3AAiNHAf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl2GEwS6c7sZ"
      },
      "source": [
        "### Group values around keys for the final DataFrame"
      ],
      "id": "pl2GEwS6c7sZ"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pZN7eKekc7aL"
      },
      "outputs": [],
      "source": [
        "df = df.group_by(keys).agg([\n",
        "    pl.col(\"quantity\").sum().alias(\"quantity\"),\n",
        "    pl.col(\"holiday\").max().alias(\"holiday\")\n",
        "]).join(\n",
        "    previous_month_values.select(city_month_keys + monthly_shifts_names),\n",
        "    on=city_month_keys,\n",
        "    how=\"left\"\n",
        ").join(\n",
        "    previous_quantity_values.select(pdv_week_keys + quantity_shifts_names),\n",
        "    on=pdv_week_keys,\n",
        "    how=\"left\"\n",
        ").filter(\n",
        "    pl.col('month').eq(max_month + LEADING_MONTHS)\n",
        ").with_columns([\n",
        "    (pl.col('previous_month_discount_sum') / pl.col('previous_month_gross_value_sum')).fill_null(0).replace([np.inf, -np.inf], 0).alias('discount_rate_month'),\n",
        "    (pl.col('previous_month_gross_profit_sum') / pl.col('previous_month_gross_value_sum')).fill_null(0).replace([np.inf, -np.inf], 0).alias('profit_margin_month'),\n",
        "    pl.lit(LEADING_MONTHS).cast(pl.Int8).alias('month'),\n",
        "    pl.col('week_of_year') - max_week,\n",
        "]).drop(['quantity'])"
      ],
      "id": "pZN7eKekc7aL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUcaohTjE5yn"
      },
      "source": [
        "## SAVING THE DATA"
      ],
      "id": "RUcaohTjE5yn"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PEiBMs7ru_c4"
      },
      "outputs": [],
      "source": [
        "df.write_parquet('../../data/processed/processed_production.parquet')"
      ],
      "id": "PEiBMs7ru_c4"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}