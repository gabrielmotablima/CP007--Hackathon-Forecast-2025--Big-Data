{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703f0c27",
   "metadata": {},
   "source": [
    "# Bagging Ensemble with XGBoost for Demand Forecasting\n",
    "\n",
    "This notebook uses Optuna to optimize a `BaggingRegressor` that uses `XGBoost` as its base estimator. The goal is to find the best hyperparameters for both the bagging ensemble and the underlying XGBoost models to create a powerful, variance-reduced forecasting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2285e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import yaml\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Modeling & Optimization\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "import optuna\n",
    "\n",
    "# Our functions\n",
    "import utils.bagging_utils_gpu as utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21530e28",
   "metadata": {},
   "source": [
    "# 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eacba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"params/bagging_params.yml\", \"r\") as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "RANDOM_STATE = configs['RANDOM_STATE']\n",
    "NUMBER_OF_FOLDS = configs['NUMBER_OF_FOLDS']\n",
    "FEATURE_COLUMNS = configs['FEATURES']\n",
    "LABEL_COLUMNS = configs['TARGET']\n",
    "PREPROCESSING = configs['PREPROCESSING']\n",
    "OPTUNA_PARAMS = configs['OPTUNA_PARAMS']\n",
    "MODEL_RANGE_PARAMS = OPTUNA_PARAMS['BAGGING_XGBOOST']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac4e26",
   "metadata": {},
   "source": [
    "# 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef02f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading and preparing data...\")\n",
    "df = pd.read_parquet('../../data/processed/processed_data.parquet')\n",
    "df['week_of_year'] = df['week_of_year'].astype(int)\n",
    "df = df.sort_values([\"week_of_year\", \"internal_product_id\", \"internal_store_id\"]).reset_index(drop=True)\n",
    "\n",
    "# Manual Pre-processing\n",
    "df = df[~pd.isna(df['premise'])]\n",
    "df['premise'] = df['premise'].map({'Off Premise': 1, 'On Premise': 0}).astype(int)\n",
    "cols_sum = df.columns[df.columns.str.contains(\"sum\")]\n",
    "df[cols_sum] = df[cols_sum].fillna(0)\n",
    "\n",
    "print(f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7252a21",
   "metadata": {},
   "source": [
    "# 3. Feature Separation and Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe99bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = [col for col in df[FEATURE_COLUMNS].select_dtypes(np.number).columns if col not in PREPROCESSING.get('CYCLICAL_FEATURES', {})]\n",
    "CATEGORICAL_COLUMNS = [col for col in df[FEATURE_COLUMNS].select_dtypes('object').columns]\n",
    "\n",
    "X_train = df.loc[df.month != 12, FEATURE_COLUMNS]\n",
    "y_train = df.loc[df.month != 12, [LABEL_COLUMNS]]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=NUMBER_OF_FOLDS)\n",
    "\n",
    "print(\"Data split and CV folds created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea75f6",
   "metadata": {},
   "source": [
    "## 4. Optimize Bagging Ensemble with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a57e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(study_name='bagging_xgb_optimization', directions=['minimize', 'minimize'])\n",
    "study.set_metric_names([\"score_validation\", \"score_overfitting\"])\n",
    "\n",
    "objective_function = utils.create_objective_function(\n",
    "    hyperparam_ranges=MODEL_RANGE_PARAMS,\n",
    "    tscv=tscv,\n",
    "    x_data=[X_train, y_train],\n",
    "    columns_to_use=[FEATURE_COLUMNS, LABEL_COLUMNS, NUMERIC_COLUMNS, CATEGORICAL_COLUMNS],\n",
    "    preprocessing=PREPROCESSING,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "study.optimize(objective_function, n_trials=OPTUNA_PARAMS['TRIALS'])\n",
    "\n",
    "print(\"Optimization finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, best_params = utils.get_best_params(study)\n",
    "print(\"Best parameters found for the Bagging+XGBoost ensemble:\")\n",
    "print(json.dumps(best_params, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee4401",
   "metadata": {},
   "source": [
    "## 5. Fit Final Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting final BaggingRegressor with all available data...\")\n",
    "\n",
    "X_train_full = df[FEATURE_COLUMNS]\n",
    "y_train_full = df[[LABEL_COLUMNS]]\n",
    "\n",
    "# --- Reconstruct the optimized Bagging Regressor ---\n",
    "\n",
    "bagging_final_params = {k.replace('bagging_', ''): v for k, v in best_params.items() if k.startswith('bagging_')}\n",
    "xgb_final_params = {k.replace('xgb_', ''): v for k, v in best_params.items() if k.startswith('xgb_')}\n",
    "\n",
    "final_base_estimator = XGBRegressor(**xgb_final_params, device='cuda', tree_method='hist', random_state=RANDOM_STATE)\n",
    "final_bagging_regressor = BaggingRegressor(\n",
    "    estimator=final_base_estimator,\n",
    "    **bagging_final_params,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Final ensemble configured:\")\n",
    "print(final_bagging_regressor)\n",
    "\n",
    "# --- Build and fit the final pipeline ---\n",
    "pipe_preproc = utils.create_preprocessing_pipeline(PREPROCESSING, NUMERIC_COLUMNS, CATEGORICAL_COLUMNS)\n",
    "ttr = TransformedTargetRegressor(regressor=final_bagging_regressor, func=np.log1p, inverse_func=np.expm1)\n",
    "final_pipeline = Pipeline(steps=[('preprocessor', pipe_preproc), ('model', ttr)])\n",
    "\n",
    "final_pipeline.fit(X_train_full, y_train_full.values.ravel())\n",
    "\n",
    "print(\"\\nFinal pipeline fitted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b99db",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9982589",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = f\"outputs/{dt.datetime.now().strftime('%Y%m%d%H%M')}_BAGGING_XGBOOST/\"\n",
    "output_model_directory = os.path.join(output_directory, 'model')\n",
    "output_params_directory = os.path.join(output_directory, 'params')\n",
    "output_optuna_directory = os.path.join(output_directory, 'study')\n",
    "\n",
    "for directory in [output_model_directory, output_params_directory, output_optuna_directory]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(f\"Created output directory: {output_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final pipeline\n",
    "with open(os.path.join(output_model_directory, 'pipeline.pkl'), 'wb') as f:\n",
    "    pickle.dump(final_pipeline, f)\n",
    "\n",
    "# Save the parameters used\n",
    "with open(os.path.join(output_params_directory, 'experiment_params.json'), 'w') as f:\n",
    "    serializable_params = {k: (float(v) if isinstance(v, (np.floating, np.integer)) else v) for k, v in best_params.items()}\n",
    "    configs_all = {**configs, 'BEST_PARAMS': serializable_params}\n",
    "    json.dump(configs_all, f, indent=4)\n",
    "\n",
    "# Save the Optuna study object\n",
    "with open(os.path.join(output_optuna_directory, 'study.pkl'), 'wb') as f:\n",
    "    pickle.dump(study, f)\n",
    "\n",
    "print(\"All artifacts saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
